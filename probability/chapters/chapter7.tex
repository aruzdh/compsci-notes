\chapter{Teorema del Límite Central}
\section{Vectores Aleatorios y Función de Probabilidad Conjunta}
\subsection{Vector Vleatorio}

Se sabe que una \textit{variable aleatoria es una función} que tiene \textit{dominio en el espacio muestral} $\Omega$ y \textit{toma valores en} $\mathbb R$. Sin embargo, este concepto se puede expandir a $\mathbb R^n$, y por tanto, definir una función $f: \Omega \longrightarrow \mathbb R^n$. Visto de otra manera:
\[w \mapsto (\mathcal X_1(w), \mathcal X_2(w), \cdots, \mathcal X_n(w)) = \mathcal X(w)\]
A esta nueva función se le conoce como \textit{vector aleatorio}.

\dfn{Vector Aleatorio}{
  Decimos que $\mathcal X$ es un \textbf{vector aleatorio} si
  \[\mathcal X = (\mathcal X_1(w), \mathcal X_2(w), \cdots, \mathcal X_n(w))\]
  donde cada $\mathcal X_i$ es una variable aleatoria.
}

\ex{Vector Aleatorio}{
  Se lanza un dado 2 veces. Definimos las siguientes variables aleatorias.
  \[\mathcal X_1 := \text{Valor máximo de los lanzamientos}\]
  \[\mathcal X_2 := \text{Valor mínimo de los lanzamientos}\]
  \[\mathcal X_3 := \text{La suma de los valores en los lanzamientos}\]

  Con lo anterior, nuestro espacio muestral es el siguiente.
\[
  \Omega = \left\{
  \begin{matrix}
  (1,1) & (1,2) & (1,3) & (1,4) & (1,5) & (1,6) \\
  (2,1) & (2,2) & (2,3) & (2,4) & (2,5) & (2,6) \\
  (3,1) & (3,2) & (3,3) & (3,4) & (3,5) & (3,6) \\
  (4,1) & (4,2) & (4,3) & (4,4) & (4,5) & (4,6) \\
  (5,1) & (5,2) & (5,3) & (5,4) & (5,5) & (5,6) \\
  (6,1) & (6,2) & (6,3) & (6,4) & (6,5) & (6,6)
  \end{matrix}
  \right\}
\]
  Supongamos que en los dados obtuvimos los valores de 4 y 3. En este caso nuestro vector $\mathcal X$ se ve como:
  \[\mathcal X((4,3)) = (\mathcal X_1((3,4)), \, \mathcal X_2((3,4)), \, \mathcal X_3((3,4))) = (4,3,7)\]
  Notese que se obtuvo un vector en $\mathbb R^3$.
}

Al igual que las variables aleatorias, los vectores aleatorios se dividen en \textit{discretos} y \textit{continuos} de acuerdo con las variables que los definen. 

\dfn{Vector Aleatorio Discreto}{
  Decimos que un \textit{vector aleatorio} $\mathcal X = (\mathcal X_1, \mathcal X_2, \cdots, \mathcal X_n)$ es \textbf{discreto} si $\forall i = 1, \cdots, n, \, \mathcal X_i$ es una variable aleatoria discreta.
}

\dfn{Vector Aleatorio Continuo}{
  Decimos que un \textit{vector aleatorio} $\mathcal X = (\mathcal X_1, \mathcal X_2, \cdots, \mathcal X_n)$ es \textbf{continuo} si $\forall i = 1, \cdots, n, \, \mathcal X_i$ es una variable aleatoria continua.
}

\subsection{Función de Probabilidad Conjunta}
De la misma manera, podemos calcular la probabilidad de que el vector aleatorio tome ciertos valores con la siguiente definición.

\dfn{Función de Probabilidad Conjunta}{
  La \textbf{función de probabilidad conjunta} de dos variables aleatorias $\mathcal X$ y $\mathcal Y$, denotada $f_{\mathcal X, \mathcal Y}(x,y)$, es la función que asigna a cada par de valores $(x,y)$ la probabilidad de que las variables aleatorias $\mathcal X$ y $\mathcal Y$ tomen esos valores simultáneamente.

  \[
    f_{\mathcal X, \mathcal Y}(x,y) = P(\mathcal X = x, \, \mathcal Y = y)
  \]
  donde $(x,y)$ está en la imagen de $(\mathcal X, \, \mathcal Y)$. En caso contrario, la función vale 0.
}

\nt{
  La definición anterior está dada para 2 variables aleatorias, pero se puede extender para \textit{n} variables con $P(\mathcal X_1 = x_1, \, \mathcal X_2 = x_2, \, \cdots, \, \mathcal X_n = x_n)$
}

\ex{Función de Probabilidad Conjunta}{
  Se lanza una moneda justa tres veces consecutivas y deseamos analizar el comportamiento de las siguientes variables aleatorias.

  \[\mathcal Y = \text{Número de soles obtenidos en las primeros dos lanzamientos}\]
  \[\mathcal X = \text{Número de soles obtenidos en las últimos dos lanzamientos}\]

  El espacio muestral se puede ver como
  \[
    \Omega = \left\{
      \begin{matrix}
        AAA & ASA \\
        AAS & ASS \\
        SAA & SAS \\
        SSA & SSS \\
      \end{matrix}
    \right\}
  \]
  Con esto tenemos que nuestras variables pueden tomar los valores $\{0,1,2\}$, y entonces podemos obtener las siguientes probabilidades.

  \begin{align*}
    P(\mathcal X = 0, \, \mathcal Y = 0) = \sfrac18 \\
    P(\mathcal X = 0, \, \mathcal Y = 1) = \sfrac18 \\ 
    P(\mathcal X = 0, \, \mathcal Y = 2) = 0 \\ 
    P(\mathcal X = 1, \, \mathcal Y = 0) = \sfrac18 \\ 
    P(\mathcal X = 1, \, \mathcal Y = 1) = \sfrac14 \\ 
    P(\mathcal X = 1, \, \mathcal Y = 2) = \sfrac18 \\ 
    P(\mathcal X = 2, \, \mathcal Y = 0) = 0 \\ 
    P(\mathcal X = 2, \, \mathcal Y = 1) = \sfrac18 \\ 
    P(\mathcal X = 2, \, \mathcal Y = 2) = \sfrac18 \\ 
  \end{align*}
}

\section{Independencia y Distribuciones Marginales}

\subsection{Variables Aleatorias Dndependientes}
Recordemos que si dos eventos $A, B \in \mathcal F$ son independientes, entonces
\[P(A \cap B) = P(A)P(B)\]

\dfn{Variables Aleatorias Independientes}{
  Decimos que las variables aleatorias $\mcX$ y $\mcY$ son \textbf{variables aleatorias independientes} si 
  \[\forall B, C \subseteq \bbR,\, P(\mcX \in B, \, \mcY \in C) = P(\mcX \in B)P(\mcY \in C)\]
}

Ademas, podemos extenderlo de la siguiente manera.
\[f_{\mcX, \mcY}(x,y) = P(\mcX = x, \, \mcY = y) = P(\mcX = x)P(\mcY = y) = f_{\mcX}(x) f_{\mcY}(y)\]

\nt{
  Si $\mcX$ y $\mcY$ son variables aleatorias \textit{discretas}, entonces $f_{\mcX}$, y $f_{\mcY}$ son funciones de probabilidad y $f_{\mcX, \mcY}$ es la función de probabilidad conjunta.
  \newpara
  Si $\mcX$ y $\mcY$ son variables aleatorias \textit{continuas}, entonces $f_{\mcX}$, y $f_{\mcY}$ son funciones de densidad y $f_{\mcX, \mcY}$ es la función de densidad conjunta.
}

\subsection{Distribuciones Marginales}

\dfn{Distribuciones Marginales (caso discreto)}{
  Sea ($\mcX, \mcY$) un vector aleatorio \textit{discreto}. Definimos la \textbf{función de probabilidad marginal} de $\mcX$ y $\mcY$ de la siguiente forma.

  \[f_{\mcX}(x) = P(\mcX = x) = \sum_j f(x,j) = \sum_j P(\mcX = x, \, \mcY = j)\]
  \[f_{\mcY}(y) = P(\mcY = y) = \sum_i f(i,y) = \sum_i P(\mcX = i, \, \mcY = y)\]

  Donde $j$ son todos los valores que toma $\mcY$, mientras que $i$ son todos los valores que toma $\mcX$.
}

\dfn{Distribuciones marginales (caso continuo)}{
  Sea ($\mcX, \mcY$) un vector aleatorio \textit{continuo}. Definimos la \textbf{función de probabilidad marginal} de $\mcX$ y $\mcY$ de la siguiente forma.

  \[f_{\mcX}(x) = \int_{-\infty}^{\infty} f_{\mcX, \mcY}(x,y) \,dy \]
  \[f_{\mcY}(y) = \int_{-\infty}^{\infty} f_{\mcX, \mcY}(x,y) \,dx \]

  Donde $j$ son todos los valores que toma $\mcY$, mientras que $i$ son todos los valores que toma $\mcX$.
}

\ex{Distribuciones Marginales}{
  Consideremos el mismo experimento del ejemplo anterior (lanzar 3 monedas justas) y las mismas variables aleatorias. Las probabilidades marginales se calculan como sigue.

  \begin{align*}
    f_{\mcX}(0) &= \sum_{i=0}^2 f_{\mcX}(0,i)\\ 
                &= \sum_{i=0}^2 P(\mcX = 0, \, \mcY = i)\\
                &= P(\mcX = 0, \, \mcX = 0) + P(\mcX = 0, \, \mcX = 1) + P(\mcX = 0, \, \mcX = 2)\\
                &= \frac18 + \frac18 + 0 = \frac14
  \end{align*}
  El resultado anterior nos dice que la probabilidad de obtener 0 soles en los últimos dos lanzamientos es de $\frac14$.

  Usando el mismo método se obtiene lo siguiente.
  \[
    P(\mcX = 0) = P(\mcX = 0, \, \mcX = 0) + P(\mcX = 0, \, \mcX = 1) + P(\mcX = 0, \, \mcX = 2) = \frac18 + \frac18 + 0 = \frac14
  \]
  \[
    P(\mcX = 1) = P(\mcX = 1, \, \mcX = 0) + P(\mcX = 1, \, \mcX = 1) + P(\mcX = 1, \, \mcX = 2) = \frac18 + \frac14 + \frac18 = \frac12
  \]
  \[
    P(\mcX = 2) = P(\mcX = 2, \, \mcX = 0) + P(\mcX = 2, \, \mcX = 1) + P(\mcX = 2, \, \mcX = 2) = 0 + \frac18 + \frac18 = \frac14
  \]
  El caso para la variables aleatorias $\mcY$ es análogo.
}

Así, podemos afirmar que, dadas dos variables aleatorias independientes $\mcX$ y $\mcY$, se tiene que

\begin{itemize}
  \item Caso discreto: $P(\mcX = x, \, \mcY = y) = P(\mcX = x)P(\mcY = y)$
  \item Caso continuo: $f_{\mcX, \mcY}(x,y) = f_{\mcX}(x) f_{\mcY}(y)$
\end{itemize}

\section{Independencia y su Relación con el Valor Esperado}
Podemos establecer una relación entre la independencia y la esperanza (valor esperado). Si consideramos dos variables aleatorias discretas independientes con $g,h : \bbR \longrightarrow \bbR$ funciones reales, entones podemos desallorar

\begin{align*}
  \E(g(\mcX)h(\mcY)) &= \sum_i \sum_j g(i)h(j)P(\mcX = i, \, \mcY = j)\\
                       &= \sum_i \sum_j g(i)h(j)P(\mcX = i)P(\mcY = j) \qquad (\text{por independencia}) \\
                       &= \sum_i g(i) P(\mcX = i) \sum_j h(j) P(\mcY = j)\\
                       &= \E(g(\mcX))\E(h(\mcY))
\end{align*}

\mprop{Independencia y su Relación con el Valor Esperado}{
  Sean $\mcX$ y $\mcY$ variables aleatorias independientes, entonces
  \[\E(g(\mcX)h(\mcY)) = \E(g(\mcX))\E(h(\mcY))\]
}

\nt{
  Tener $\E(g(\mcX)h(\mcY)) = \E(g(\mcX))\bbE(h(\mcY))$, no necesariamente implica independencia.
}

Así, cuando hay independiencia
\begin{itemize}
  \item $\E(\mcX \mcY) = \E(\mcX) \E(\mcY)$
  \item $\E (\mcX + \mcY) = \E (\mcX) + \E(\mcY)$
\end{itemize}

\subsection{Varianza cuando hay Independiencia}
Con las últimas observaciones podemos demostrar la siguiente proposición.

\mprop{Varianza cuando hay Independencia}{
  Sean $\mcX$ y $\mcY$ variables aleatorias independientes, entonces
  \[\Var(\mcX + \mcY) = \Var(\mcX) + \Var(\mcY)\]
}

\begin{myproof}
  De forma general sabemos que
  \[\Var(\mcX + \mcY) = \Var(\mcX) + \Var(\mcY) + 2(\E(\mcX \mcY) - \E(\mcX)\E(\mcY)) \neq \Var(\mcX) + \Var(\mcY)\]

  Sin embargo, por independencia tenemos
  \[\E(\mcX \mcY) = \E(\mcX)\E(\mcY) \Longrightarrow \E(\mcX \mcY) - \E(\mcX)\E(\mcY) = 0\]

  \[\therefore \Var(\mcX + \mcY) = \Var(\mcX) + \Var(\mcY)\]
\end{myproof}

De manera general, se cumple que si $\mcX_1, \mcX_2, \cdots , \mcX_n$ son variables aleatorias independientes, entonces
\[
  \E(f_1(\mcX_1)f_2(\mcX_2) \cdots f_n(\mcX_n)) = \prod_{i = 1}^n \E(f_i(\mcX_i)) = \E(f_1(\mcX_1))\E(f_2(\mcX_2))\cdots \E(f_n(\mcX_n))
\]
\subsection{Función Generadora de Momentos cuando hay Independencia}

\mprop{Independencia y Función generadora de momentos}{
  Sean $\mcX$ y $\mcY$ variables aleatorias independientes con funciones generadoras do momentos $M_{\mcX}(t)$ y $M_{\mcY}(t)$, entonces
  \[M_{\mcX + \mcY}(t) = M_{\mcX}(t)M_{\mcY}(t)\]

  Además, si $\mcX_1, \mcX_2, \cdots , \mcX_n$ son independientes con funciones generadoras de momentos $M_1(t), M_2(t), \cdots , M_n(t)$, entonces
  \[\mcZ = \sum_{i = 1}^n \mcX_i\]
  tiene función generadora de momentos
  \[M_{\mcZ} = \prod_{i=1}^n M_i(t)\]
}

\begin{myproof}
  \begin{align*}
    M_{\mcX + \mcY}(t) &= \E(e^{t(\mcX + \mcY)})\\
                       &= \E(e^{t\mcX}e^{t\mcY})\\
                       &= \E(e^{t\mcX})\E(e^{t\mcY}) \quad (\text {por independencia})\\
                       &= M_{\mcX}(t)M_{\mcY}(t)
  \end{align*}

  El caso para la variable aleatoria $\mcZ$ es análogo.
\end{myproof}

\nt{
  La proposición anterior se cumple para la función generadora de probabilidad.
  \newpara
  Si $\mcX_1, \mcX_2, \cdots , \mcX_n$ son variables aleatorias independientes, entonces la función de probabilidad de $\sum_{i=1}^n \mcX_i$ es
  \[G_{\mcX_1 + \mcX_2 + \cdots + \mcX_n} = \prod_{i=1}^n G_i(t)\]
}

\ex{Función generadora de momentos de la suma de v.a.i}{
  Encuentra la distribución de $\mcX + \mcY$ donde $\mcX \sim Poi(\lambda)$ y $\mcY \sim Poi(\mu)$ son independientes.

  Primero calculamos la función generadora de momentos de $\mcX + \mcY$.
  \[M_{\mcX + \mcY}(t)= M_{\mcX}(t)M_{\mcY}(t) \quad (\text{por independencia})\]

  Por otro lado, sabemos que
  \[M_{\mcX}(t) = e^{-\lambda(1-e^t)}\]
  \[M_{\mcY}(t) = e^{-\mu(1-e^t)}\]

  Lo anterior implica que

  \[
    M_{\mcX + \mcY}(t) = e^{-\lambda(1-e^t)}e^{-\mu(1-e^t)} = e^{-(\lambda + \mu)(1-e^t)}
  \]
  \[\, \therefore \mcX + \mcY \sim Poi(\lambda + \mu)\]
}

\ex{Función generadora de momentos de la suma de v.a.i}{
  Encuentra la distribución de $\mcX + \mcY$ donde $\mcX \sim Bin(n,p)$ y $\mcY \sim Bin(m,p)$ son independientes.

  Se tiene lo siguiente.
  \[M_{\mcX + \mcY}(t)= M_{\mcX}(t)M_{\mcY}(t)\]

  Sabemos que
  \[
    M_{\mcX}(t) = \sum_{k=0}^n e^{tk} \binom nk p^k (1-p)^{n-k}
    \sum_{k=0}^n \binom nk (e^t p)^k (1-p)^{n-k}
    = (1-p + e^t p)^n
  \]
  Así

  \[
    M_{\mcX + \mcY}(t) = (1-p + e^t p)^n (1-p + e^t p)^m = (1-p + e^t p)^{m + n}
  \]
  \[\, \therefore \mcX + \mcY \sim Bin(n + m, p)\]
}

\section{Desigualdad de Markov}

\mprop{Desigualdad de Markov}{
  Si $\mcX$ es una variable aleatoria que solo toma valores no negativos, entonces para cualquier $a > 0$ se cumple lo siguiente.
  \[P(\mcX \ge a) \le \frac{\E(\mcX)}a \]
}

\begin{myproof}
  \begin{align*}
  \E(\mcX) &= \int_{0}^{\infty} x f(x)dx = \int_{0}^{a} x f(x)dx + \int_{a}^{\infty} x f(x)dx \\[2ex]
  &\geq \underbrace{\int_{0}^{a} x f(x)dx}_{\geq 0} + a \int_{a}^{\infty} f(x)dx \geq a \int_{a}^{\infty} f(x)dx \\
  \end{align*}
  \[\therefore \, P(\mcX \ge a) \le \frac{\E(\mcX)}a \]
\end{myproof}

\nt{
  Si $\mcX = (\mcY - \mu)^2$ y $a = k^2 \sigma^2$ donde $\sigma^2 = \Var(\mcX) > 0$ se puede deducir el Teorema de Chebyshev.
}

Estas desigualdades nos permiten encontrar cotas para las probabilidades cuando solo la esperanza y/o la varianza son conocidas.

\ex{Desigualdad de Markov}{
  Supongamos que sabemos que el número de productos fabricados durante una semana es una variable aleatoria con esperanza de 500.

  1. ¿Qué podemos decir sobre la probabilidad de que la producción de una semana sea al menos de 1000?

  2. Si la varianza de esta producción semanal es 100, ¿qué podemos decir sobre la probabilidad de que la producción semanal esté entre 400  y 600?

  Primero definimos una variable aleatoria.
  \[\mcX = \text{ \# productos fabricados por semana} \quad \text{ con } \quad \E(\mcX) = 500 \quad \text{ y } \quad \Var(\mcX) = 100\]

  1. $P(\mcX \ge 1000) = \frac{\bbE(\mcX)}{1000} = \frac{500}{1000} = \frac12$

  2. $\sigma^2 = \E(\abs*{\mcX - \mu}^2) = 100$

  Queremos calcular $P(400 \le \mcX \le 600)$. Usando el teorema de Chebyshev.
  \[P(\abs*{\mcX - \mu} \le k\sigma) \ge 1 - \frac1{k^2}\]
  \[\Longrightarrow P(\abs*{\mcX - 500} \le k10) = P(-k10 \le \mcX - 500 \le k10) 
  = P(-k10 + 500 \le \mcX \le k10 + 500) \]

  Si sustituimos $k = 10$ obtenemos lo siguiente.
  \[P(400 \le \mcX \le 600) = 1 - \frac{1}{100} = \frac{99}{100} = 0.99\]
}

\section{Ley Fuerte de los Grandes Números}
Antes de presentar el resultado principal de este aparto se da la siguiente definición.

\subsection{Media Muestral}
\dfn{Media Muestral}{
  Sea $\{\mcX_n\}_{n = 1,2,\cdots}$ usa sucesión de variables aleatorias independientes e idénticamente distribuidas. Se define la \textbf{media muestral} como sigue.
  \[\overline{\mcX} = \frac{S_n}n\]
donde 
\[S_n = \sum_{i=1}^n \mcX_i\]
}

\ex{Media Muestral}{
  Sea $\mcX_i \sim Ber(p)$ que vale 1 cuando ganamos un volado, y 0 cuando perdemos.
  En este caso, la información que nos da $S_n$ es el número de volados ganados.
}

\subsection{Teorema: Ley Fuerte de los Grandes Números}
\thm{Ley fuerte de los grandes números}{
  Sea $\{\mcX_n\}$ variables aleatorias independientes e idénticamente distribuidas con media común $\mu \in \bbR,~ (\E(\mcX_n) = \mu~ \forall n \in \bbN)$. Entonces,
  \[\overline{\mcX} \to \mu \qquad \text{casi seguramente}\]

  Es decir,
  \[\lim_{n \to \infty} \frac{\mcX_1 + \mcX_2 + \cdots + \mcX_n}n = \mu\]
  Salvo un conjunto $N \in \mcF$ tal que $P(N) = 0$
}

Otra manera de observar el teorema es la siguiente.
\[P\parens*{\lim_{n \to \infty} \frac{\mcX_1 + \mcX_2 + \cdots + \mcX_n}n = \mu} = 1\]
Donde la convergencia dentro de la probabilidad es puntual.

\ex{Ley Fuerte de los Grandes Números}{
  Supongamos que lanzamos un dado justo muchas veces. Sean $\mcX_i$ las variables aleatorias que representan el resultado del \textit{i}-ésimo lanzamiento. Como el dado es justo, el valor esperado de cada $\mcX_i$ es
  \[\mu = \E(\mcX_i) = \frac{1 + 2 + 3 + 4 + 5 + 6}6 = 3.5\]
  
  En este caso, la Ley de los grandes números nos asegura que
  \[\lim_{n \to \infty} \frac1n \sum_{i=1}^n \mcX_i = 3.5 \quad \text{casi seguramente}\]

  Graficamente, se puede observar la convergencia del promedio $\frac1n \sum_{i=1}^n \mcX_i$ hacia $\mu = 3.5$ a medida que aumenta el número de lanzamientos $n$.
}

\nt{
  Se llama ley "Fuerte" porque la convergencia es casi seguramente. La convergencia casi seguramente significa que la convergencia es puntual salvo en un conjunto $N$ tal que $P(N) = 0$
}

\subsection{Convergencia Puntual}
\dfn{Convergencia Puntual}{
  Sean $\{\mcX_n\}_{n \ge 1}$ una sucesión de variables aleatorias definidas sobre el mismo espacio de probabilidad, y sea $\mcX$ una variable aleatoria también definida en el mismo espacio.

  $\mcX_n \to \mcX$ puntualmente si
  \[\forall w \in \Omega \text{ se satisface que } \lim_{n \to \infty} \mcX_n(w) = \mcX(w)\]
  Dados $w \in \Omega$ y $\epsilon > 0$, $\exists N = N(w, \epsilon) \in \bbN$ tal que si $n \ge N \Longrightarrow \abs*{\mcX_n(w) - \mcX(w)} < \epsilon$
}

\section{Teorema del Límite Central}
Además de su importancia e interés teórica, este teorema nos proporciona un método simple para aproximar probabilidades de sumas de variables aleatorias independientes.

\thm{Teorema del límite central}{
  Sean $\mcX_1, \mcX_2, \cdots$ una sucesión de variables aleatorias independientes e idénticamente distribuidas con $\E(\mcX_i) = \mu ~ \forall i$, y $\Var(\mcX_i) = \sigma^2~ \forall i$. Entonces la función de distribución de $F_n$ de la variable aleatoria $\mcY_n$ con
  \[\mcY_n = \frac{\mcX_1 + \mcX_2 + \cdots + \mcX_n - n\mu}{\sigma \sqrt n}\]
  converge a la distribución $N(0,1)$ si $n \to \infty$, es decir,
  \[\lim_{n \to \infty}P\parens*{\frac{\mcX_1 + \mcX_2 + \cdots + \mcX_n - n\mu}{\sigma \sqrt n} \le a} = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-\frac{x^2}2} \,dx\]
}

\nt{
  Notemos que no necesitamos saber la distribución de las $\mcX_i$.
}

