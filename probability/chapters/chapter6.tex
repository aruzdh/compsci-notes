\chapter{Momentos de Variables Aleatorias}
\section{Esperanza}
\subsection{Definición (caso discreto)}

\dfn{Esperanza (caso discreto)}{
  Si $\mathcal X$ es una variable aleatoria \textit{discreta} con función de probabilidad $f_{\mcX}(x) = P(\mathcal X = x)$. Entonces la \textbf{esperanza o valor esperado} de $\mathcal X$, denotada $\E(\mathcal X)$, está definida de la siguiente manera.
  \[\E(\mathcal X) = \sum_i i P(\mathcal X = i)\]
  Donde la suma es sobre todos los valores que toma la variable aleatoria $\mathcal X$, y por ende, $\E(\mathcal X)$, es un valor real, no una variable aleatoria.
}

\nt{
  El valor esperado es un \textit{promedio ponderado} de los posibles valores que $\mathcal X$ puede tomar. Cada valor que $\mathcal X$ puede tomar se pondera por su respectiva probabilidad.
}

\ex{Esperanza}{
  Sea la variable aleatoria $\mathcal \sim Ber(p)$.
  \[\E(\mathcal X) = 0 \cdot P(\mathcal X = 0) + 1 \cdot P(\mathcal X = 1) = 0 \cdot (1-p) + 1 \cdot p = p\]
}

\ex{Esperanza}{
  Encuentra el valor esperado de $\mathcal X$ donde $\mathcal X$ es el resultado del lanzamiento de un dado justo.
  \begin{align*}
    \E(\mathcal X) &= \sum_{i = 1}^6 i P(\mathcal X = i) = \sum_{i = 1}^6 i \frac16 = \frac16 \sum_{i = 1}^6\\
                  &= \frac16 (1+2+3+4+5+6) = \frac{21}6 = 3.5 \in \mathbb R
  \end{align*}
}

\nt{
  Aunque una variable aleatoria $\mathcal X$ solo tome valores enteros, $\E(\mathcal X)$ no necesariamente es un número entero.
}

\subsection{Definición (caso continuo)}
\dfn{Esperanza (caso continuo)}{
  Si $\mathcal X$ es una variable aleatoria continua con función de densidad $f_{\mcX}(x)$. Definimos su valor esperado como sigue a continuación.
  \[\E(\mathcal X) = \int_{-\infty}^{\infty}x f_{\mcX}(x)\,dx\]
}

\ex{Esperanza}{
  Sea $\mathcal X \sim exp(\lambda)$ con $f_{\mcX}(x) = \lambda e^{-\lambda x}~ \mathbb 1_{(0, \infty)}^{(x)}$. Se tiene lo siguiente.
  \begin{align*}
    \E(\mathcal X) &= \lambda \int_{-\infty}^{\infty} x e^{-\lambda x} 1_{(0, \infty)}^{(x)}~dx\\
                  &= \lambda \int_0^{\infty}x e^{-\lambda x}~dx\\
                  &= \lambda [- \frac{x}{\lambda}e^{- \lambda x} \Big |_0^{\infty} + \frac1{\lambda}\int_0^{\infty}e^{-\lambda x}~dx]\\
                  &= -\frac1{\lambda}e^{-\lambda x} \Big |_0^{\infty} = \frac{e^{\lambda (0)}}{\lambda} = \frac1 \lambda
  \end{align*}

  \[\therefore\,{\text{Si } \mathcal X \sim exp(\lambda), \text{ entonces } \E(\mathcal X) = \frac1 \lambda}\]
}

\ex{Esperanza}{
  Sea $\mathcal X \sim Bin(n,p)$. Demuestra que $\E(\mathcal X) = np$
  \begin{align*}
    \E(\mathcal X) = \sum_{i=0}^{n} i \binom{n}{i} p^i (1-p)^{n-i} &= \sum_{i=1}^{n} \binom{n}{i} i p^i (1-p)^{n-i} \\
    &= \sum_{i=1}^{n} \frac{n!}{i!(n-i)!} i p^i (1-p)^{n-i} \\
    &= \sum_{i=1}^{n} \frac{n!}{(i-1)!(n-i)!} p^i (1-p)^{n-i} \\
    &= np \sum_{i=1}^{n} \frac{(n-1)!}{(i-1)!(n-i)!} p^{i-1} (1-p)^{n-i} \\
    &= np \sum_{i=1}^{n} \binom{n-1}{i-1} p^{i-1} (1-p)^{n-i} \\
    &= np \sum_{j=0}^{n-1} \binom{n-1}{j} p^{j} (1-p)^{n-1-j} \quad k = i-1 \\
    &= np (p + (1-p))^{n-1} = np
  \end{align*}
}

\subsection{Esperanza de una Composición}
\mprop{}{
  Sea $\mathcal X$ una variable aleatoria discreta, y \textit{g} una función real. Entonces
  \[\E(g(\mathcal X)) = \sum_i g(i)P(\mathcal X = i)\]
  donde $\mathcal Y = g(\mathcal X)$
}

\mprop{}{
  Sea $\mathcal X$ una variable aleatoria continua con función de densidad $f_{\mathcal X}$, y \textit{g} una función real. Entonces
  \[\E(g(\mathcal X)) = \int_{-\infty}^{\infty}g(x)f_{\mathcal X}(x)\,dx\]
  donde $\mathcal Y = g(\mathcal X)$
}

\ex{Esperanza de una Composición}{
  Sea $\mathcal X$ una variable aleatoria tal que
  \[P(\mathcal X = -1) = 0.2 \qquad P(\mathcal X = 0) = 0.5 \qquad P(\mathcal X = 1) = 0.3\]
  Calcula la $\E(\mathcal X^2)$.
  \begin{enumerate}[a)]
    \item Usando $\mathcal Y = \mathcal X^2$ y calculando $P(\mathcal Y = i)$

      $\mathcal X^2 = \mathcal Y \in \{0,1\}$
      \[P(\mathcal Y = 0) = P(\mathcal X = 0) = 0.5\]
      \[P(\mathcal Y = 1) = P(\mathcal X = 1) + P(\mathcal X = -1) = 0.3 + 0.2 = 0.5\]
      Así,
      \[\E(\mathcal X^2) = 0 \cdot P(\mathcal X^2 = 0) + 1 \cdot P(\mathcal X^2 = 1) = 1 \cdot P(\mathcal Y = 1) = 0.5\]
    \item Usando la proposición
      \begin{align*}
        \E(\mathcal X^2) &= \sum_{i = -1}^1 (i)^2 P(\mathcal X = i)\\
                        &= (-1)^2 \cdot P(\mathcal X = -1) + 0^2 \cdot P(\mathcal X = 0) + 1^2 \cdot P(\mathcal X = 1)\\
                        &= 1 \cdot (0.2) + 0 \cdot (0.5) + 1 \cdot (0.3)\\
                        &= 0.5
      \end{align*}

  \end{enumerate}
}

\subsection{Propiedades}
Las siguientes son propiedades de la esperanza o valor esperado. Sea $\mathcal X,~ \mathcal Y$ variables aleatoria con función de densidad $f_{\mathcal X},~ f_{\mathcal Y}$, respectivamente.
\begin{enumerate}
  \item $E(c) = c,~ c \in \mathbb R$
    \begin{myproof}
      \[E(c) = \int_{-\infty}^{\infty} c f_{\mathcal X}(x)~dx = c \int_{-\infty}^{\infty} f_{\mathcal X}(x)~dx = c \cdot 1 = c\]
    \end{myproof}
  \item $E(c \mathcal X) = c E(\mathcal X),~ c \in \mathbb R$
    \begin{myproof}
      \[E(c\mathcal X) = \int_{-\infty}^{\infty} cx f_{\mathcal X}(x)~dx = c \int_{-\infty}^{\infty} xf_{\mathcal X}(x)~dx = c E(\mathcal X)\]
    \end{myproof}
  \item $E(\mathcal X + \mathcal Y) = E(\mathcal X) + E(\mathcal Y)$
  \item Si $P(\mathcal X \ge 0) = 1$ (es decir, $\mathcal X \ge 0$ casi seguramente), entonces $E(\mathcal X) \ge 0$
    \begin{myproof}
      \[E(\mathcal X) = \int_{-\infty}^{\infty} x f_{\mathcal X}(x)~dx = \int_{-\infty}^{0} xf_{\mathcal X}(x)~dx + \int_{0}^{\infty} xf_{\mathcal X}(x)~dx\]
      Por hipótesis se concluye lo siguiente.
      \[E(\mathcal X) = \int_{0}^{\infty} xf_{\mathcal X}(x)~dx \ge 0\]
    \end{myproof}
  \item Si $P(\mathcal X \le \mathcal Y) = 1$ (es decir, $\mathcal X \le \mathcal Y$ casi seguramente), entonces $E(\mathcal X) \le E(\mathcal Y)$
    \begin{myproof}
      \[P(\mathcal X \le \mathcal Y) = 1 \Longrightarrow P(\mathcal Y - \mathcal X \ge 0) = 1 \Longrightarrow E(\mathcal Y - \mathcal X) \ge 0 ~~~(por \textit{(4)})\]
      Por \textit{(3)} se tiene lo siguiente.
      \[E(\mathcal Y - \mathcal X) = E(\mathcal Y) + E(\mathcal {-X}) = E(\mathcal Y) - E(\mathcal X) \ge 0 \Longrightarrow E(\mathcal X) \le E(\mathcal Y) \]
    \end{myproof}
  \item $|E(\mathcal X)| \le E(|\mathcal X|)$
    \begin{myproof}
      Notemos que $- |\mathcal X| \le \mathcal X \le |\mathcal X|$ casi seguramente.
      Por \textit{(5)} se tiene que
      \[-E(|\mathcal X|) \le E(\mathcal X) \le E(|\mathcal X|)
        \Longleftrightarrow
      |E(\mathcal X)| \le E(|\mathcal X|)|\]
    \end{myproof}
\end{enumerate}

\nt{
  La propiedad \textit{2} y \textit{3} nos dicen que \textit{la esperanza es lineal}.
}

\section{Varianza}
\subsection{Definicion}

\dfn{Varianza}{
  La \textbf{varianza} de una variable aleatoria $\mathcal X$, denotada por $\Var(\mathcal X)$, se define de la siguiente forma.
  \[\Var(\mathcal X) = \E([\mathcal X - \E(\mathcal X)]^2)\]
  Cuando dicha esperanza existe.
  \newpara
  De este modo, existen dos casos.
  \begin{itemize}
    \item Caso discreto.
      \[\Var(\mathcal X) = \E([\mathcal X - \E(\mathcal X)]^2) = \sum_i (i - \E(\mathcal X))^2 P(\mathcal X = i)\]
    \item Caso continuo.
      \[\Var(\mathcal X) = \E([\mathcal X - \E(\mathcal X)]^2) = \int_{-\infty}^\infty (x - \E(\mathcal X))^2 f_{\mathcal X} (x)\,dx\]
  \end{itemize}
}

\nt {
  Retomando el ejemplo de una variable aleatoria normal, podemos decir que la varianza ($\sigma ^2$) nos indica que tanto se alejan los datos del valor esperado (esperanza).
}

\subsection{Propiedades}
Las siguientes son propiedades de la varianza. Sean $\mathcal X, \mathcal Y$ variables aleatorias con varianza finita y $c \in \mathbb R$.

\begin{enumerate}
\item $\Var(\mathcal X) \ge 0$
  \begin{myproof}
    $\Var(\mathcal X) = \E([\mathcal X - \E(\mathcal X)]^2)$ donde podemos notar que $(\mathcal X - \E(\mathcal X))^2 \ge 0$
    \[\therefore \, \E([\mathcal X - \mathbb E(\mathcal X)]^2) \ge 0 \]
  \end{myproof}
\item $\Var(c) = 0$
  \begin{myproof}
    \[\Var(c) = \E([c - \mathbb E(c)]^2) = \E([c - c]^2) = \E(0) = 0\]
  \end{myproof}
\item $\Var(c \mathcal X) = c^2 \Var(\mathcal X)$
  \begin{myproof}
    \[\Var(c\mathcal X) = \E([c\mathcal X - \E(c\mathcal X)]^2) = \E([c\mathcal X - c\E(\mathcal X)]^2) = \E(c^2[\mathcal X - \E(\mathcal X)]^2) = c^2\E([\mathcal X - \E(\mathcal X)]^2) = c^2 \Var(\mathcal X)\]
  \end{myproof}
\item $\Var(\mathcal X + c) = \Var(\mathcal X)$
  \begin{myproof}
    \[\Var(\mathcal X + c) = \E([\mathcal X + c - \E(\mathcal X + c)]^2) = \E([\mathcal X + c - \E(\mathcal X) - c]^2) = \E([\mathcal X - \E(\mathcal X)]^2) = \Var(\mathcal X)\]
  \end{myproof}
\item $\Var(\mathcal X) = \E(\mathcal X^2) - [\E(\mathcal X)]^2$
  \begin{myproof}
    \begin{align*}
      \Var(\mathcal X) &= \E([\mathcal X - \E(\mathcal X)]^2)\\
                             &= \E(\mathcal X^2 - 2\mathcal X\E(\mathcal X) + (\E(\mathcal X))^2)\\
                             &= \E(\mathcal X^2) - 2 \E(\mathcal X) \E(\mathcal X) + (\E(\mathcal X))^2 = \E(\mathcal X) - (\E(\mathcal X))^2
    \end{align*}
  \end{myproof}
\item En general, $\Var(\mathcal X + \mathcal Y) \neq \Var(\mathcal X) +\Var(\mathcal Y)$
  \begin{myproof}
    \begin{align*}
      \Var(\mathcal X + \mathcal Y) &= \E \left([(\mathcal X + \mathcal Y) - \E(\mathcal X + \mathcal Y)]^2\right) \\
                      &= \E \left([(\mathcal X + \mathcal Y)]^2 - 2(\mathcal X + \mathcal Y)\E(\mathcal X + \mathcal Y) + (\E(\mathcal X + \mathcal Y))^2\right) \\
                      &= \E \left([\mathcal X^2 + 2\mathcal X \mathcal Y + \mathcal Y^2] - 2(\mathcal X + \mathcal Y)(\E(\mathcal X) + \E(\mathcal Y)) + (\E(\mathcal X)^2 + 2\E(\mathcal X)\E(\mathcal Y) + \E(\mathcal Y)^2)\right) \\
                      &= \E \left(\mathcal X^2 + 2\mathcal X \mathcal Y + \mathcal Y^2 - [2\mathcal X\E(\mathcal X) + 2\mathcal X\E(\mathcal Y) + 2\mathcal Y\E(\mathcal X) + 2\mathcal Y\E(\mathcal Y)] \right. \\
                      &\qquad\qquad \left. + [\E(\mathcal X)^2 + 2\E(\mathcal X)\E(\mathcal Y) + \E(\mathcal Y)^2]\right) \\
                      &= \E \left([\mathcal X - \E(\mathcal X)]^2 + [\mathcal Y - \E(\mathcal Y)]^2 + 2\mathcal X \mathcal Y - 2\mathcal X\E(\mathcal Y) - 2\mathcal Y\E(\mathcal X) + 2\E(\mathcal X)\E(\mathcal Y)\right) \\
                      &= \Var(\mathcal X) + \Var(\mathcal Y) + 2\E(\mathcal X \mathcal Y) - 2\E(\mathcal X)\E(\mathcal Y) - 2\E(\mathcal X)\E(\mathcal Y) + 2\E(\mathcal X)\E(\mathcal Y) \\
                      &= \Var(\mathcal X) + \Var(\mathcal Y) + 2(\E(\mathcal X \mathcal Y) - \E(\mathcal X)\E(\mathcal Y)) \neq \Var(\mathcal X) + \Var(\mathcal Y)
    \end{align*}
  \end{myproof}
\end{enumerate}

\ex{Varianza}{
  Calcular $\Var(\mathcal X)$ si $\mathcal X \sim \text{exp}(\lambda)$.
  \newpara
  De un ejemplo anterior sabemos que $\E(\mathcal X) = \frac1\lambda$. Usando la propiedad 5 podemos hacer lo siguiente.
  \[\Var(\mathcal X) = \E(\mathcal X^2) - [\E(\mathcal X)]^2 = \E (\mathcal X^2) = (\frac1\lambda)^2\]

  Por otro lado,
  \[
    \E(\mathcal X^2) = \int_{-\infty}^\infty x^2 \lambda e^{-\lambda x}\mathbb 1_{(0, \infty)}^{(x)}dx = \lambda \int_0^\infty x^2 e^{-\lambda x}dx
  \]
  Usando la siguiente sustitución
  \[
    u = x^2 \Longrightarrow du = 2xdx \qquad dv = e^{-\lambda x}dx \Longrightarrow v = -\frac{e^{-\lambda x}}\lambda
  \]
  obtenemos
  \begin{align*}
    \E (X^2) &= \lambda \left[-\frac{x^2e^{-\lambda x}}{\lambda}\bigg|_0^\infty + \frac{2}{\lambda}\int_0^\infty xe^{-\lambda x}dx\right] = \lambda\left[\frac{2}{\lambda^2}\int_0^\infty x\lambda e^{-\lambda x}dx\right] \\
    &= \lambda\left[\frac{2}{\lambda^2}\int_0^\infty xf_X(x)dx\right] = \lambda\left[\frac{2}{\lambda^2}\mathbb{E}(X)\right] = \lambda\left[\frac{2}{\lambda^2}\frac{1}{\lambda}\right] = \frac{2}{\lambda^2} = \mathbb{E}(X^2)
  \end{align*}

  \[
  \therefore \Var(\mathcal X) = \E(\mathcal X^2) - (\frac1\lambda)^2 = \frac2{\lambda^2} - \frac1{\lambda^2} = \frac1{\lambda^2}
  \]
}

\subsection{Desviación Estándar}

\dfn{Desviación Estándar}{
  Sea $\mathcal X$ una variable aleatoria con varianza $\Var(\mathcal X)$, entonces se define la \textbf{desviación estándar} de $\mathcal X$ de la siguiente forma.
  \[\sigma = \sqrt{\Var(\mathcal X)}\]
}

\subsection{Teorema de Chebyshev}
\thm{Teorema de Chebyshev}{
  Sea $\mathcal X$ una variable aleatoria con esperanza $\mu$ y desviación estándar $\sigma$, entonces para cualquier constante $k > 0$ la probabilidad es al menos $1 - \frac1{k^2}$ de que $\mathcal X$ asumirá un valor dentro de $k$ desviaciones estándar de la media (valor esperado), es decir,
  \[P(|\mathcal X - \mu| \le k \sigma) = P(-k \sigma \le \mathcal X - \mu \le k \sigma) \ge 1 - \frac1{k^2}\]
}

\ex{Esperanza y Varianza}{
  Sea $\mcX \sim \Gamma(\alpha, \lambda)$. Calcula $\E (\mcX)$ y $\Var(\mcX)$.
  \begin{itemize}
  \item Por un lado
  \begin{align*}
    \E(\mcX) &= \int_{-\infty}^{\infty} x\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}\mathbb 1_{(0,\infty)}^{(x)}dx = \int_0^{\infty} x\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}dx \\
  &= \frac{1}{\lambda}\int_0^{\infty} \frac{\lambda^{\alpha+1}}{\Gamma(\alpha)}x^{\alpha+1-1}e^{-\lambda x}dx \quad \text{Usando que } \Gamma(\alpha+1) = \alpha\Gamma(\alpha) \text{ sustituimos,}\\
  &= \frac{\alpha}{\lambda}\int_0^{\infty} \frac{\lambda^{\alpha+1}}{\Gamma(\alpha+1)}x^{\alpha+1-1}e^{-\lambda x}dx = \frac{\alpha}{\lambda}\int_0^{\infty} f_{X'}(x)dx \quad \text{Donde } \mcX' \sim \Gamma(\alpha+1,\lambda)\\
  &= \frac{\alpha}{\lambda}\int_0^{\infty} f_{\mcX'}(x)dx = \frac{\alpha}{\lambda}
  \end{align*}

  \item Por otro lado para calcular $\Var(X)$ primero calculamos lo siguiente,
  \begin{align*}
  \E (X^2) &= \int_0^{\infty} \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha+2-1}e^{-\lambda x}dx = \frac{1}{\lambda^2}\int_0^{\infty} \frac{\lambda^{\alpha+2}}{\Gamma(\alpha)}x^{\alpha+2-1}e^{-\lambda x}dx
  \end{align*}
  Realizamos una sustitución similar a la del inciso anterior usando que:

  \[\Gamma(\alpha + 2) = (\alpha + 1)\Gamma(\alpha + 1) = (\alpha + 1)(\alpha)\Gamma(\alpha)\]

  \[\E (X^2) = \frac{\alpha(\alpha + 1)}{\lambda^2} \underbrace{\int_0^{\infty} \frac{\lambda^{\alpha+2}}{\Gamma(\alpha+2)}x^{\alpha+2-1}e^{-\lambda x}dx}_{1}\]

  Usando el mismo argumento del inciso anterior: $(\mcX' \sim \Gamma(\alpha + 2, \lambda))$.

  \[\E(\mathcal X^2) = \frac{\alpha(\alpha + 1)}{\lambda^2}\]
  Finalmente usamos la propiedad 5 de la varianza.

  \[\Var(X) = \E (X^2) - [\E (X)]^2 = \frac{\alpha(\alpha + 1)}{\lambda^2} - \left(\frac{\alpha}{\lambda}\right)^2 = \frac{\alpha}{\lambda^2}\]

  \end{itemize}
}

\section{Momentos de una Variable Aleatoria}

Los momentos de una variable aleatoria son medidas que describen diferentes aspectos de su comportamiento. Nos ayudan a entender cosas como el promedio, la dispersión, y la forma de la distribución de los valores. En general, los momentos nos ofrecen una forma matemática de capturar información clave sobre cómo se comportan los datos o resultados asociados a esa variable.

\subsection{Definición}
\dfn{Momentos de una Variable Aleatoria}{
  Sea $\mathcal X$ una variable aleatoria, definimos el \textbf{$n$-ésimo momento} de $\mathcal X$ como:
  \[\E(\mathcal X^n), \quad n \in \mathbb N\]
}

\subsection{Momentos Importantes de una Variable Aleatoria}

Algunos de los momentos más importantes son los siguientes.
\begin{itemize}
  \item $\E(\mathcal X)$. La esperanza es el primer momento.
  \item $\E([\mathcal X - \mu]^2)$. El segundo momento central.
  \item $\E([\mathcal X - \mu]^n)$. El \textit{n}-ésimo momento central.
  \item $\E(\abs*{\mathcal X}^n)$. El \textit{n}-ésimo momento absoluto.
  \item $\E(\abs*{\mathcal X - \mu}^n)$. El \textit{n}-ésimo momento absoluto central.
\end{itemize}

\subsection{Función Generadora de Momentos}

\dfn{Función Generadora de Momentos}{
  La \textbf{función generadora de momentos} de una variable aleatoria $\mathcal X$ está definida por
  \[M_{\mathcal X} = \E(e^{t\mathcal X})\]
Lo que implica que $M_{\mathcal X} (t)$ se encuentra bien definida para valores de $t$ tales que $\E(|e^{t \mathcal X}|) < \infty$
}

\ex{Función Generadora de Momentos}{
  Calculemos $M_{\mathcal X}(t)$ si $\mathcal X \sim \Gamma(\alpha, \lambda)$ con $\alpha, \lambda > 0$.

  \[
    f_{\mathcal X}(x) =
    \begin{cases}
      \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha -1}e^{-\lambda x} & x > 0 \\
      0 &\text{otro caso}
    \end{cases}
  \]
  Entonces
  \begin{align*}
    M_{\mathcal X}(t) &= \E(e^{t \mathcal X}) = \int_{-\infty}^{\infty} e^{tx}\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha -1}e^{-\lambda x} \mathbb 1_{(0, \infty)}^{(x)}dx = \int_0^{\infty} e^{tx}\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha -1}e^{-\lambda x} dx\\
                    &= \lambda^\alpha \int_0^{\infty} \frac1{\Gamma(\alpha)}x^{\alpha -1}e^{tx-\lambda x} dx
  \end{align*}
  Multiplicando por $\frac{(\lambda - t)^\alpha}{(\lambda - t)^\alpha}$
  \begin{align*}
    M_{\mathcal X} (t) &= \frac{\lambda^\alpha}{(\lambda - t)^\alpha} \int_0^{\infty} \frac{(\lambda - t)^\alpha}{\Gamma(\alpha)}x^{\alpha -1}e^{-(\lambda - t)x} dx = \frac{\lambda^\alpha}{(\lambda - t)^\alpha} \int_0^{\infty} f_{\mathcal X'}(x)dx = \frac{\lambda^\alpha}{(\lambda - t)^\alpha}
  \end{align*}
  Donde $\mathcal X' \sim \Gamma(\alpha, \lambda - t)$ y además $\lambda - t > 0 \Rightarrow \lambda > t$. Por lo tanto, la función generadora de momentos de $\mathcal X$ es
  \[M_{\mathcal X} (t) = (\frac{\lambda}{\lambda - t})^2, \quad \lambda > t\]
}

\ex{Función Generadora de Momentos}{
  Calcular $M_{\mathcal X}(t)$ donde $\mathcal X \sim \text{Poi}(\lambda)$
  \newpara
  Primera recordemos que
  \[f_{\mathcal X}(x) = \frac{e^{-\lambda} \lambda^x}{x!}, \quad x = 0, 1, 2, \cdots\]
  Entonces
  \[M_{\mathcal X}(t) = \E(e^{-\lambda \mathcal X}) = \sum_{i = 0}^\infty \frac{e^{ti}e^{-\lambda}\lambda^i}{i!} = e^{-\lambda} \sum_{i = 0}^\infty \frac{e^{ti}\lambda^i}{i!} = e^{-\lambda} \sum_{i = 0}^\infty \frac{(e^t \lambda)^i}{i!} = e^{-\lambda}e^{e^t\lambda}\]
  Esto último se obtuvo usando la serie de la exponencial: 
  \[e^x = \sum_{k = 0}^\infty \frac{x^k}{k!}\]
  \[\therefore M_{\mathcal X}(t) = e^{-\lambda}e^{e^t \lambda} = e^{-\lambda(1 - e^t)}\]
}

\subsection{Propiedades de la Función Generadora de Momentos}

\mprop{}{
  Sea $\mathcal X$ una variable aleatoria con función generadora de momentos $M_{\mathcal X} (t)$. Entonces se cumple lo siguiente.
  \begin{enumerate}
    \item \[\frac{d^n}{dt^n} M_{\mathcal X}(t) \bigg |_{t = 0} = \E(\mathcal X^n)\]
    \item \[\E(\mathcal X^n) < \infty \text{ cuando } t \in (-s, s) \text{ con } s > 0 \text{ suficientemente pequeño}\]
    \item \[M_{\mathcal X}(t) = \sum_{n = 0}^\infty \frac{t^n}{n!} \E(\mathcal X^n) \leftarrow \quad \text{Serie de Taylor} \]
  \end{enumerate}
}

\subsection{Función Característica}
Aunque la función generadora de momentos no siempre existe, la siguiente existe para todo $t \in \mathbb R$.

\dfn{Función característica}{
  Sea $\mathcal X$ una variable aleatoria, definimos la \textbf{función característica} de $\mathcal X$ como sigue.
  \[\Phi_{\mathcal X} (t)=\E(e^{it \mathcal X}) = \E(\cos (t\mathcal X) + i \sin(t \mathcal X))\]
}

\section{Función Generadora de Probabilidad}
\subsection{Definición}

\dfn{Función generadora de probabilidad}{
  Sea $\mathcal X$ una variable aleatoria que toma valores enteros positivos $\mathbb Z^+$. La \textbf{función generadora de probabilidad} se define de la siguiente manera.
  \[G(t) = \E(t^{\mathcal X})\]
}

\ex{Función generadora de probabilidad}{
  Calculemos la función generadora de probabilidad para $\mathcal X \sim \text{Poi}(\lambda)$

  \begin{align*}
    G(t) &= \E(t^{\mathcal X}) = \sum_{n=0}^{\infty} t^n P(X = n) = \sum_{n=0}^{\infty} t^n \frac{e^{-\lambda}\lambda^n}{n!} \\
  &= e^{-\lambda} \sum_{n=0}^{\infty} \frac{(t\lambda)^n}{n!} = e^{-\lambda}e^{\lambda t} = e^{-\lambda(1-t)}
  \end{align*}
}
Esta función nos sirve principalmente para conocer los momentos factoriales de una variable aleatoria $\mathcal X$, es decir:
  \[
  \lim_{t \to 1} \frac{d^n}{dt^n}G(t) = \E(\mathcal X(\mathcal X-1)(\mathcal X-2)...(\mathcal X-n+1))
\]
A este último se le conoce como el n-ésimo momento factorial. Notemos que:
\begin{itemize}
    \item El primer momento factorial es la esperanza $(n=1)$ $\E(\mathcal X)$
    \item Segundo momento factorial $(n=2)$ $\E(\mathcal X(\mathcal X-1))=\E(\mathcal X^2)-\E(\mathcal X)$
    \item Tercer momento factorial $(n=3)$ $\E(\mathcal X(\mathcal X-1)(\mathcal X-2))=\E((\mathcal X^2-X)(\mathcal X-2))=\E(\mathcal X^3-3\mathcal X^2+2\mathcal X)$
\end{itemize}

\subsection{Variables Aleatorias Iguales en Distribución}
Algo que también es importante distinguir es cuando las variables aleatorias tienen la misma distribución como en el siguiente ejemplo.\\
Definimos los siguientes experimentos:
\begin{itemize}
    \item El lanzamiento de una moneda justa, $\mathcal X=\begin{cases}
        -1 & \text{si sale sol}\\
        1 & \text{si sale águila}
    \end{cases}$

    \item Al tomar una carta en una baraja de 52 cartas, $\mathcal Y=\begin{cases}
        100 & \text{si sale pica ó corazón}\\
        0 & \text{si sale diamante ó trébol}
    \end{cases}$

    \item Al lanzar un dado justo, $\mathcal Z=\begin{cases}
        1 & \text{si sale un número no par}\\
        0 & \text{si sale un número par}
    \end{cases}$
\end{itemize}
En este caso observamos que $\mathcal X \neq \mathcal Y \neq \mathcal Z$, sin embargo, $\mathcal X \sim \text{Ber}(1/2)$, $\mathcal Y \sim \text{Ber}(1/2)$, $\mathcal Z \sim \text{Ber}(1/2)$. Lo anterior significa que las variables son iguales en distribución y lo denotamos por $\mathcal X \stackrel{d}{\sim} \mathcal Y \stackrel{d}{\sim} \mathcal Z$, es decir $F_{\mathcal X}(y)=F_{\mathcal Y}(y)=F_{\mathcal Z}(y) \quad \forall y \in \mathbb{R}$.

\dfn{Variables Aleatorias Iguales en Distribución}{
  Sean $\mathcal X$ y $\mathcal Y$ dos variables aleatorias. Se dice que son iguales en distribución si
  \[P(\mathcal X \in B) = P(\mathcal Y \in B),\]
  Esto último también se denota como $\mathcal X \stackrel{d}{=} \mathcal Y$.
}

\ex{Igualdad en distribución}{
  Uno de los ejemplos más comunes de esta propiedad es que las variables aleatorias $\mathcal X \sim \Gamma(1, \lambda)$ y $\mathcal Y \sim \text{Exp}(\lambda)$ son iguales en distribución ($\mathcal X \stackrel{d}{=} \mathcal Y$)
}

\subsection{Propiedad de igualdad en distribución}
\mprop{Igualdad en distribución}{
  Sean $\mathcal X$ y $\mathcal Y$ dos variables aleatorias con función generadora de momentos $M_{\mathcal X}(t)$ y $M_{\mathcal Y} (t)$, respectivamente, y además se cumple que $M_{\mathcal X}(t) = M_{\mathcal Y}(t)$ para todo $t \in (-s, s), s > 0$. Entonces
  \[\mathcal X \stackrel{d}{=} \mathcal Y\]
}

\nt{
  La proposición anterior también se cumple para la función generadora de probabilidad, es decir, si en lugar de usar $M_{\mathcal X}(t)$ y $M_{\mathcal Y}(t)$ usamos $G_{\mathcal X}(t)$ y $G_{\mathcal Y}(t)$ para todo $t \in (-s, s), s > 0$. Entonces $\mathcal X \stackrel{d}{=} \mathcal Y$.
}

