\chapter{Distribuciones}
\section{Distribuciones Aleatorias Discretas}
\subsection{Destribución Bernoulli}

\dfn{}{
  Sea $\mathcal X$ una \textit{variable aleatoria discreta}. Diremos que $\mathcal X$ tiene \textbf{distribución Bernoulli} ($\mathcal X \sim Ber(p)$) con parámetro \textit p, donde $p \in [0,1]$ si satisface lo siguiente
  \[
    \mathcal X = 
    \begin{cases}
    0 ~~~~~ \text{con probabilidad } (1 - p) & \\
    1 ~~~~~ \text{con probabilidad } p & \\
    \end{cases}
  \]
}

\noindent Generalmente decimos que si $\mathcal X(w) = 1$, entonces "\textit{ocurrió un éxito}", y si $\mathcal X(w) = 0$, "\textit{ocurrió un fracaso"}.
\nt{
  A \textit p se le conoce como la \textbf{probabilidad de éxito}
}

\dfn{}{
  Si $\mathcal X \sim Ber(p)$. Definimos su \textbf{función de probabilidad} como
  \[f(k) = P(\mathcal X = k) = 
 \begin{cases}
   P ~~~~~~~~\text{si } k = 1 \\
   1-P ~~~\text{si } k = 0\\
 \end{cases}\]
}

\dfn{}{
  Si $\mathcal X \sim Ber(p)$. Definimos su \textbf{función de distribución} como
  \[
  F_{\mathcal X}(k) = P(\chi \le k)= 
  \begin{cases}
  0 ~~~~~~~~~~~~~~~ \text{si } k < 0 & \\
  1 - p ~~~~~~~~~~ \text{si } 0 \le k < 1 & \\
  1 ~~~~~~~~~~~~~~~ \text{si } 1 \le k & \\
  \end{cases}
\]
}

\subsection{Variable Aleatoria Binomial}
\dfn{}{
  Sea $\mathcal X$ una \textit{variable aleatoria} tal que cuenta el número de éxitos en \textit {n experimentos Bernoulli independientes}. Entonces $\mathcal X$ tiene \textbf{distribución Binomial} con parámetros \textit{p, n}. Se denota como
  \[\mathcal X \sim Bin(n,p)\]
  donde \textit n es el \textit{número de experimentos Bernoulli}, y \textit p es la \textit{probabilidad de éxito de cada experimento}.
}

\dfn{}{
  Si $\mathcal X \sim Bin(n,p)$. Definimos la \textbf{función de probabilidad de masa binomial} como
  \[f(k) = P(\mathcal X = k) = \binom{n}{k}p^n(1-p)^{n - k}\]
}

\dfn{}{
  Si $\mathcal X \sim Bin(n,p)$. Definimos su \textbf{función de distribución} como
  \[F_{\mathcal X}(k) = P(\mathcal X \le k) = \sum_{i = 0}^k \binom{n}{i}p^i(1-p)^{n - i}\]
}

\subsection{Variable Aleatoria Poisson}

\dfn{}{
  Sea $Y \sim Bin(n, \frac{\lambda}{n})$ con $\lambda > 0$, es decir, \textit {Y es una variable aleatorial binomial} donde la probabilidad de éxito es $\frac{\lambda}{n}$.
  \[ \lim_{n \to \infty}P(Y = k) = \frac{\lambda^k}{k!}e^{-\lambda} = P(Z = k) = f(k)\]
  donde \textit f es la \textbf{función de probabilidad de masa} de una variable aleatoria $Z \sim Poi(\lambda)$
}

\nt{
  Si $Y \sim Bin(n,p)$ y \textit {p es pequeño} y \textit {n suficientemente grande}. Entonces se puede calcular la distribución de \textit Y unsando la \textbf{distribución de Poisson}.
}

\dfn{}{
  Una \textit{variable aleatoria con distribución poisson} $\mathcal X \sim Poi(\lambda)$ con $\lambda > 0$ tiene función de probabilidad de masa
  \[P(\mathcal X = k) = f(k) = \frac{e^{-\lambda}\lambda^k}{k!},~ k = 0, 1, \cdots\]
}

\subsection{Variable Aleatoria Geométrica}
Supongamos que van a desarrollarse experimentos Bernoulli independientes con parámetro de éxito \textit p.

\dfn{}{
  La \textbf{variable aleatoria geométrica} se define como
  \[\mathcal X = \text{"\# de fracasos antes de obtener un el primer éxito"}\]
}

Entonces
\begin{align*}
  &f(0) = P(\mathcal X = 0) = P(\text{"Éxito"}) = p \\
  &f(1) = P(\mathcal X = 1) = P(\text{F~E}) = (1 - p) p \\
  &f(2) = P(\mathcal X = 2) = P(\text{F~F~E}) = (1 - p)^2 p \\
  &\cdots \\
  &f(k) = P(\mathcal X = k) = (1-p)^k p \\
\end{align*}

\dfn{}{
  Si $\mathcal X$ en una \textit{variable aleatoria geométrica}. Definimos la \textbf{función de probabilidad} como

  \[f(k) = P(\mathcal X = k) = (1-p)^k p\]
}

\noindent \textit f satisface las propiedades de una función de probabilidad
\begin{enumerate}
  \item \[f(k) \le 0\]
  \item \[\sum_{k = 0}^{\infty} f(k) = 1\]
\end{enumerate}

\dfn{}{
  Si $\mathcal X$ en una \textit{variable aleatoria geométrica}. Definimos su \textbf{función de distribución} como

  \[F_{\mathcal X}(k) = P(\mathcal X \le k) = \sum_{i = 0}^k(1-p)^i p\]
}


\subsection{Variable Aleatoria Binamial Negativa}

Supongamos que van a desarrollarse experimentos Bernoulli independientes con parámetro de éxito \textit p.
\dfn{}{
  La \textbf{variable aleatoria binomial negativa} se define como
  \[\mathcal X = \text{\# de ensayos hasta obtener r éxitos}\]
}

\dfn{}{
  Si $\mathcal X$ en una \textit{variable aleatoria binomial negativa}. Definimos la \textbf{función de probabilidad} como

  \[f(k) = P(\mathcal X = k) = \binom{k-1}{r-1}p^r(1-p)^{k-r} = \frac{(k-1)!}{(k-r)!(r-1)!}p^r(1-p)^{k-r} \]
  donde \textit r es el número de éxitos, y \textit k el número de ensayos.
}

\dfn{}{
  Si $\mathcal X$ en una \textit{variable aleatoria binomial negativa}. Definimos su \textbf{función de distribución} como

  \[F_{\mathcal X}(k) = P(\mathcal X \le k) =\sum_{i = 0}^k \binom{i-1}{r-1}p^r(1-p)^{i-r} = \sum_{i = 0}^k \frac{(i-1)!}{(i-r)!(r-1)!}p^r(1-p)^{i-r} \]
  donde \textit r es el número de éxitos, y \textit k el número de ensayos.
}

\subsection{Variable Aleatoria Uniforme}
\dfn{}{
  Una \textit{variable aleatoria $\mathcal X$} se dice que es \textbf{uniforme} sobre $\{a_1, a_2, \cdots, a_n\}$ donde $a_i \in \mathbb R$ si
  \[P(\mathcal X = a_i) = \frac{1}{n},~ \forall i \in \{1, 2, 
  \cdots n\}\]
}

\subsection{Variable Aleatoria Hipergeométrica}

Supongamos que en una caja hay \textit N pelotas, \textit m azules y \textit{N - m} amarillas. Se escogen \textit n pelotas al azar.

\[P(\mathcal X = k) = \frac{\binom{m}{k} \binom{N - m}{n-k} }{\binom{N}{n}}\]

\noindent Todos los experimentos que tengan un contexto similar se modelan con una variable aleatoria hipergeométrica.

\section{Distribuciones Absolutamente Continuas}

