\section{The Change of Coordinate Matrix}

\thm{}{
Let $\beta$ and $\beta '$ be two ordered bases for a finite-dimensional vector space $V$, and let $Q = [I_V]_{\beta '}^\beta$. Then
\begin{enumerate}
  \item $Q$ is invertible.
  \item For any $v \in V$, $[v]_\beta = Q[v]_\beta$.
\end{enumerate}
}

The matrix $Q = [I_V]_{\beta '}^\beta$ defined in the previous theorem is called a \textbf{change of coordinate matrix}. Because of part \textit{(b)} of the theorem, we say that $Q$ \textbf{changes $\beta '$-coordinates into $\beta$-coordinates}.

\nt{
  Notice that if $Q$ \textbf{changes $\beta '$-coordinates into $\beta$-coordinates}, then $Q^{-1}$ \textbf{changes $\beta$-coordinates into $\beta '$-coordinates}.
}

\ex{The Change of Coordinate Matrix}{
  In $\mathbb R^2$, let $\beta = \{(1, 1), (1, -1)\}$ and $\beta ' = \{(2, 4), (3,1)\}$. Since
  \[
    (2,4) = 3(1,1) - 1(1, -1)
    \qquad
    \text{and}
    \qquad
    (3,1) = 2(1,1) + 1(1, -1)
  \]
  the matrix that changes $\beta '$-coordinates into $\beta$-coordinates is
  \[
    \begin{pmatrix}
      3 & 2 \\
      -1 & 1 \\
    \end{pmatrix}
  \]
  Thus, for instance,
  \[[(2, 4)]_\beta = Q[(2, 4)]_{\beta '} 
  = Q \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 3 \\ -1 \end{pmatrix}
\]
}

For the remainder of this section, we consider only linear transformations that map a vector space $V$ into itself. Such a linear transformation is called a \textbf{linear operator} on $V$.

\thm{}{
  Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $\beta$ and $\beta '$ be ordered bases for $V$. Suppose that  $Q$ is the change of coordinate matrix that chages \textbf{changes $\beta '$-coordinates into $\beta$-coordinates}. Then
  \[[T]_{\beta '} = Q^{-1} [T]_\beta Q \]
}

\ex{}{}

\cor{}{
Let $A \in M_{n \times n}(\mathbb K)$, and let $\gamma$ be an ordered basis for $\mathbb K^n$. Then $[L_A]_\gamma = Q^{-1} A Q$, where $Q$ is the $n \times n$ matrix whose $jth$ columm is the $jth$ vector of $\gamma$.
}

\ex{}{}

\dfn{}{
  Let $A$ and $B$ be matrices in $M_{n \times n}(\mathbb K)$. We say that $B$ is \textbf{similar} to $A$ if there exists an invertible matrix $Q$ such that $B = Q^{-1} A Q$.
}

\nt {
  Observe that the relation of similarity is an equivalence relation. So we need only say that $A$ and $B$ are similar.
}

If $T$ is a linear operator on a finite-dimensional vector space $V$, and if $\beta$ and $\beta '$ are any ordered bases for $V$, then $[T]_\beta '$ is similar to $[T]_\beta$.

The last theorem can be generalized to allow $T : V \rightarrow W$, where $V$ is distinct from $W$. In this case, we can change bases in $V$ as well as in $W$.
